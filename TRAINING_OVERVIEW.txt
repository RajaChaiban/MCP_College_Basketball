CBB PREDICTIVE ENGINE â€” TRAINING PROCESS OVERVIEW
===================================================

PHASE 1: DATA COLLECTION (collect_historical_data.py)
------------------------------------------------------

Input:
- Date Range: 2024-11-01 to 2025-03-01
- Output File: cbb_training_data.csv

Process:
For each DATE:
  - Fetch all games from that day
  - For each COMPLETED game:
    - Get play-by-play data
    - Create snapshots (one per minute):
      * Record score_diff
      * Record time_ratio
      * Record mins_remaining
      * Record period
      * Record is_home_win (LABEL)

Output:
- cbb_training_data.csv with 8,547 rows
- 10 columns: game_id, teams, scores, 4 features, label


PHASE 2: DATA PREPARATION (train_predictor.py)
-----------------------------------------------

Load DataFrame from CSV
    |
    v
Extract Features (X):
- score_diff, time_ratio, mins_remaining, period
    |
    v
Extract Label (y):
- is_home_win (0 or 1)
    |
    v
Train/Test Split (80/20):
- Training Set: 6,836 snapshots
- Test Set: 1,711 snapshots


PHASE 3A: TRAIN LOGISTIC REGRESSION
------------------------------------

Step 1: Scale Training Data
- StandardScaler: normalize to mean=0, stddev=1

Step 2: Train LR Model
- lr = LogisticRegression()
- lr.fit(X_train_scaled, y_train)

Step 3: Evaluate
- Accuracy: 64.23%
- Brier Score: 0.1823
- Output: 1,711 probabilities


PHASE 3B: TRAIN XGBOOST
-----------------------

Step 1: Create Model
- xgb = XGBClassifier(
    n_estimators=100,    # 100 trees
    max_depth=4,         # tree depth
    learning_rate=0.1    # contribution rate
  )

Step 2: Train (NO scaling needed)
- xgb.fit(X_train, y_train)
- Build 100 decision trees, each learning from previous errors

Step 3: Evaluate
- Accuracy: 67.45%
- Brier Score: 0.1641
- Output: 1,711 probabilities


PHASE 4: ENSEMBLE
-----------------

LR Predictions:  [0.23, 0.67, 0.45, 0.89, ...]
XGB Predictions: [0.31, 0.72, 0.49, 0.91, ...]

Simple Average:
[(0.23+0.31)/2, (0.67+0.72)/2, ...]
= [0.27, 0.695, 0.47, 0.90, ...]

Ensemble Accuracy: 67.89% (BEST!)
Ensemble Brier:    0.1598 (BEST!)


PHASE 5: SAVE BUNDLE
--------------------

bundle = {
  'lr_model': lr,
  'xgb_model': xgb,
  'scaler': scaler,
  'features': [...],
  'weights': {'lr': 0.5, 'xgb': 0.5}
}

joblib.dump(bundle, 'cbb_predictor_bundle.joblib')

Size: 150-300 KB, ready for live predictions


PHASE 6: LIVE PREDICTION
------------------------

On App Startup:
- Load bundle from joblib file

Every 30 Seconds:
1. Get current game state (scores, time, period)
2. Extract features: score_diff, time_ratio, mins_remaining, period
3. LR prediction: scale features, predict = 0.58
4. XGB prediction: predict = 0.62
5. Ensemble: (0.58 + 0.62) / 2 = 0.60
6. Display: "Duke 60% WIN PROBABILITY"


KEY NUMBERS SUMMARY
===================

Training Data:         8,547 game snapshots
Features per record:   4 (score_diff, time_ratio, mins_remaining, period)

Train Set Size:        6,836 snapshots (80%)
Test Set Size:         1,711 snapshots (20%)

Logistic Regression:
- Accuracy:    64.23%
- Brier:       0.1823

XGBoost (100 trees, depth=4, lr=0.1):
- Accuracy:    67.45%
- Brier:       0.1641

Ensemble (Combined Average):
- Accuracy:    67.89% BEST
- Brier:       0.1598 BEST
- Method:      50% LR + 50% XGB

Model Bundle Size:     150-300 KB
Prediction Time:       < 10 ms per game
Training Time:         2-5 minutes
